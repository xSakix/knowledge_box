## OpenShift Serverless: Using Knative in next-generation AI applications |DevNation Tech Talk

URL: [https://www.youtube.com/watch?v=ck1DKgmPSsQ](https://www.youtube.com/watch?v=ck1DKgmPSsQ)


In a recent engaging discussion, Kevin Florentino indulged in an intriguing tech talk with an artificial intelligence (AI) enthusiast. The conversation delved into various aspects of the ever-evolving AI landscape, OpenShift Serverless technology, and the potential of Knative neural networks. Here, we condense the most essential ideas into a 800-word blog post.

The talk began with reflections on AI terminology and misconceptions, comparing the term to legendary Frankenstein's Monster. The speaker highlighted how AI's infamous reputation often overshadows its immense potential, particularly in the realms of autonomous vehicles or advanced machine learning models. He emphasized that artificial intelligence, like Genetics Metatron metaphorically discussed, is a constantly evolving field with set rules and random probability components, finding its balance through natural selection processes.

Discussing Beethoven as an AI analogy, the speaker explored the idea of creating a probabilistic model to generate music resembling his compositions. This example underscored the concept of engram-based analysis, a powerful heuristic tool capable of distinguishing plagiarism in text by analyzing word patterns and positional context. The speaker likened this approach to adaptive, rule-based knowledge building distinct from traditional random mutation methods in AI development.

Moving on to the heart of the conversation, the topic shifted to OpenShift Serverless technologies and Kubernetes, which provide a replicable, data-centric analytical approach. The speaker showcased how Knative, an extension to Kubernetes, facilitates a Next Generation AI problem space by modeling thought processes through atomic level neuron-driven generic high-level rule sets, rather than hardcoded static settings. This modular architecture allows for efficient, adaptive response systems and event-driven application deployment.

The conversation then introduced KEventing â€” an integral part of the Knative ecosystem that manages asynchronous, event-based processing without boilerplate coding. The speaker highlighted its potential in neural network applications, drawing parallels with the K native's scalable neuron components. This led to a discussion about the Knative neural approach as a foundation for Adaptive AI systems, where stateless neurons interact through memory data grids and threshold-driven events, creating complex, adaptive behavior within simple Atomic structures.

Ultimately, the talk underscored the potential of OpenShift, Kubernetes, and Knative technologies in crafting future, scalable, adaptive AI systems. The speaker encouraged developers to explore these tools, emphasizing their role in simplifying advanced infrastructure optimization and machine learning model autoscaling capabilities. With an eye on the future, the discussion closed with optimism for new possibilities arising from these emerging solutions.

In closing thoughts, we should actively consider how OpenShift Serverless, Knative neural networks, and related technologies could shape the AI landscape, offering us efficient, adaptive, and scalable solutions in the ever-evolving world of artificial intelligence.

